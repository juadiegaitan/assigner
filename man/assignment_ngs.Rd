% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/assignment_ngs.R
\name{assignment_ngs}
\alias{assignment_ngs}
\title{Assignment analysis tailored for RADseq data}
\usage{
assignment_ngs(data, assignment.analysis, sampling.method,
  adegenet.dapc.opt = "optim.a.score", adegenet.n.rep = 30,
  adegenet.training = 0.9, thl = 1, iteration.method = 10,
  subsample = NULL, iteration.subsample = 1, marker.number = "all",
  blacklist.id = NULL, blacklist.genotype = NULL,
  whitelist.markers = NULL, monomorphic.out = TRUE, snp.ld = NULL,
  common.markers = TRUE, maf.thresholds = NULL, maf.pop.num.threshold = 1,
  maf.approach = "SNP", maf.operator = "OR", max.marker = NULL,
  strata = NULL, pop.levels = NULL, pop.labels = NULL,
  pop.select = NULL, imputation.method = NULL,
  hierarchical.levels = "populations", verbose = FALSE, folder = NULL,
  filename = "assignment_data.txt", keep.gsi.files = FALSE,
  random.seed = NULL, parallel.core = parallel::detectCores() - 1)
}
\arguments{
\item{data}{12 options: VCF (SNPs or Haplotypes,
to make the vcf population ready, see details below),
plink, stacks haplotype file, genind (library(adegenet)),
genlight (library(adegenet)), gtypes (library(strataG)), genepop, DArT,
and a data frame in long/tidy or wide format.
\emph{See details} of \code{\link[radiator]{tidy_genomic_data}}.}

\item{assignment.analysis}{(character) Assignment analysis conducted with 
\code{assignment.analysis = "gsi_sim"} or 
\code{assignment.analysis = "adegenet"}.}

\item{sampling.method}{(character) Should the markers be randomly selected
\code{sampling.method == "random"} for a classic Leave-One-Out (LOO) assignment or
chosen based on ranked Fst \code{sampling.method == "ranked"}, used in a
Training-Holdout-Leave One Out (thl) assignment. 
\emph{See details}.}

\item{adegenet.dapc.opt}{(optional, character) \strong{Argument available only when 
using:
\code{assignment.analysis = "adegenet"} with
\code{sampling.method == "random"}}.

The assignment using dapc can use the optimized alpha score 
\code{adegenet.dapc.opt == "optim.a.score"} or 
cross-validation \code{adegenet.dapc.opt == "xval"}
for stability of group membership probabilities. 
For fine tuning the trade-off between power of discrimination and over-fitting.
See \pkg{adegenet} documentation for more details.
\code{adegenet.dapc.opt == "xval"} doesn't work with missing data, so it's 
only available with \strong{imputed data} (i.e. imputation.method == "rf" or "max").
With non imputed data or the default: \code{adegenet.dapc.opt == "optim.a.score"}.}

\item{adegenet.n.rep}{(optional, integer) 
When \code{adegenet.dapc.opt == "xval"}, the number of replicates to be 
carried out at each level of PC retention. 
Default: \code{adegenet.n.rep = 30}.
See \pkg{adegenet} documentation for more details.}

\item{adegenet.training}{(optional, numeric) 
When \code{adegenet.dapc.opt == "xval"}, the proportion of data (individuals) 
to be used for the training set.
Default: \code{adegenet.training = 0.9}, if all groups have >= 10 members. 
Otherwise, training.set scales automatically to the largest proportion 
that still ensures all groups will be present in both training 
and validation sets.
See \pkg{adegenet} documentation for more details.}

\item{thl}{(character, integer, proportion) For \code{sampling.method = "ranked"} only.
Default \code{thl = 1}, 1 individual sample is used as holdout. This individual is not
participating in the markers ranking. For each marker number,
the analysis will be repeated with all the indiviuals in the data set
(e.g. 500 individuals, 500 times 500, 1000, 2000 markers).
If a proportion is used e.g. \code{thl = 0.15}, 15 percent of individuals in each
populations are chosen randomly as holdout individuals.
With \code{thl = "all"} all individuals are used for ranking (not good) and
the argument \code{iteration.method = 1} is set by default.
For the other thl values, you can create different holdout individuals lists
with the \code{iteration.method} argument below (bootstrap).}

\item{iteration.method}{(integer) With random marker selection the iterations argument =
the number of iterations to repeat marker resampling. 
Default: \code{iteration.method = 10}.
With \code{marker.number = c(500, 1000)} and default iterations setting,
500 markers will be randomly chosen 10 times and 1000 markers will be randomly
chosen 10 times.

\strong{Notes:} If all the markers are used, with \code{marker.number = "all"}
or in a series of marker number groupings \code{marker.number = c(200, 500, "all")}, 
the number of iteration is automatically set to 1. The remaining groupings
are unaffected.

For the ranked method, using \code{thl = 1}, the analysis
will be repeated for each individuals in the data set for every
\code{marker.number} selected. With a proportion argument \code{thl = 0.15},
15 percent of individuals in each populations are chosen randomly as holdout
individuals and this process is reapeated the number of times chosen by the
\code{iteration.method} value.}

\item{subsample}{(Integer or Character, optional) 
With \code{subsample = 36}, 36 individuals in each populations are chosen
randomly to represent the dataset. This integer as to be smaller than the
population with min sample size, if higher, the minimum sample size found 
in the data will be used as default. In doubt, use \code{subsample = "min"},
the function will use the smallest population sample size found in the data.
Default: \code{subsample = NULL} (no subsampling).}

\item{iteration.subsample}{(Integer) The number of iterations to repeat 
subsampling.
With \code{subsample = 20} and \code{iteration.subsample = 10},
20 individuals/populations will be randomly chosen 10 times.
Default: \code{iteration.subsample = 1}.}

\item{marker.number}{(Integer or string of number or "all") Calculations with
fixed or subsample of your markers.
e.g. To test 500, 1000, 2000 and all  the markers:
\code{marker.number = c(500, 1000, 2000, "all")}.
To use only 500 makers \code{marker.number = 500}.
Default = \code{marker.number = "all"}.}

\item{blacklist.id}{(optional) A blacklist with individual ID and
a column header 'INDIVIDUALS'. The blacklist is an object in your
global environment or a file in the working directory
(e.g. "blacklist.txt"). \code{_} and \code{:} in individual's names
are changed to a dash \code{-}.
Default: \code{blacklist.id = NULL}.}

\item{blacklist.genotype}{(optional) Useful to erase genotype with below
average quality, e.g. genotype with more than 2 alleles in diploid likely
sequencing errors or genotypes with poor genotype likelihood or coverage.
The blacklist has a minimum of 2 column headers (markers and individuals).
Markers can be 1 column (CHROM or LOCUS or POS),
a combination of 2 (e.g. CHROM and POS or CHROM and LOCUS or LOCUS and POS) or
all 3 (CHROM, LOCUS, POS). The markers columns must be designated: CHROM (character
or integer) and/or LOCUS (integer) and/or POS (integer). The id column designated
INDIVIDUALS (character) columns header.
The blacklist is an object in your global environment or
a file in the working directory (e.g. "blacklist.genotype.txt").
For de novo VCF, CHROM column
with 'un' need to be changed to 1.
Marker names are cleaned of
separators that interfere with some packages or codes:
\code{/}, \code{:}, \code{-} and \code{.} are changed to an underscore
\code{_}.
Ids are also cleaned of separators that interfere with some packages or codes:
\code{_} and \code{:} are changed to a dash \code{-}.
Default: \code{blacklist.genotype = NULL} for no blacklist of
genotypes to erase.}

\item{whitelist.markers}{(optional) A whitelist containing CHROM (character
or integer) and/or LOCUS (integer) and/or
POS (integer) columns header. To filter by chromosome and/or locus and/or by snp.
The whitelist is an object in your
global environment or a file in the working directory (e.g. "whitelist.txt").
Note that \emph{de novo} CHROM column with 'un' need to be changed to 1.
In the VCF, the column ID is the LOCUS identification (VCF generated from
stacks have the SNP position on the read embedded in the ID,
so the ID = no longer represent the LOCUS). Marker names are cleaned of
separators that interfere with some packages or codes:
\code{/}, \code{:}, \code{-} and \code{.} are changed to an underscore
\code{_}.
Default \code{whitelist.markers = NULL} for no whitelist of markers.}

\item{monomorphic.out}{(optional) Should the monomorphic
markers present in the dataset be filtered out ?
Default: \code{monomorphic.out = TRUE}.}

\item{snp.ld}{(optional) \strong{For data with locus and SNP info, like VCF and DArT file}.
SNP short distance linkage disequilibrium pruning. With anonymous markers from
RADseq/GBS de novo discovery, you can minimize linkage disequilibrium (LD) by
choosing among these 4 options:
\code{snp.ld = "random"} for a random selection of 1 SNP on the read,
\code{snp.ld = "first"} for the first one on the read...,
\code{snp.ld = "last"} for the last SNP on the read and
\code{snp.ld = "middle"} for locus with > 2 SNPs/read the option to select at random
one SNP between the first and the last SNP on the read. If the locus as <= 2
SNPs on the read, the first one is selected. Note that for that last option,
the numbers are reported. For long distance linkage
disequilibrium pruning, see details below.
Default: \code{snp.ld = NULL}.}

\item{common.markers}{(optional) Logical. Default: \code{common.markers = TRUE},
will only keep markers in common (genotyped) between all the populations.}

\item{maf.thresholds}{(string, double, optional) String with
local/populations and global/overall maf thresholds, respectively.
e.g. \code{maf.thresholds = c(0.05, 0.1)} for a local maf threshold
of 0.05 and a global threshold of 0.1. Available for VCF, PLINK and data frame
files.
Default: \code{maf.thresholds = NULL}.}

\item{maf.pop.num.threshold}{(integer, optional) When maf thresholds are used,
this argument is for the number of pop required to pass the maf thresholds
to keep the locus. Default: \code{maf.pop.num.threshold = 1}}

\item{maf.approach}{(character, optional).
\code{maf.approach = "haplotype"} : looks at the minimum MAF found on the
read/haplotype. Using this option will discard all the markers/snp on
that read based on the thresholds chosen. This method is only available
for VCF and haplotype files, or tidy data frame from those file types.
\code{maf.approach = "SNP"} : treats all the SNP on the same
haplotype/read as independent. Doesn't work with haplotype file,
but does work for all other file type.
Default is \code{maf.approach = "SNP"}.}

\item{maf.operator}{(character, optional) \code{maf.operator = "AND"} or
default \code{maf.operator = "OR"}.
When filtering over LOCUS or SNP, do you want the local \code{"AND"}
global MAF to pass the thresholds, or ... you want the local \code{"OR"}
global MAF to pass the thresholds, to keep the marker?}

\item{max.marker}{(integer, optional) For large PLINK files,
useful to subsample marker number. e.g. if the data set
contains 200 000 markers and \code{max.marker = 10000}, 10000 markers are
subsampled randomly from the 200000 markers. If you need specific markers,
use \code{whitelist.markers} argument.
Default: \code{max.marker = NULL}.}

\item{strata}{(optional/required) Required for VCF and haplotypes files, 
optional for the other file formats supported. 

The strata file is a tab delimited file with 2 columns with header:
\code{INDIVIDUALS} and \code{STRATA}. With a 
data frame of genotypes the strata is the INDIVIDUALS and POP_ID columns, with
PLINK files, the \code{tfam} first 2 columns are used. 
If a \code{strata} file is specified, the strata file will have
precedence. The \code{STRATA} column can be any hierarchical grouping. 
To create a strata file see \code{\link[radiator]{individuals2strata}}.
If you have already run 
\href{http://catchenlab.life.illinois.edu/stacks/}{stacks} on your data, 
the strata file is similar to a stacks `population map file`, make sure you 
have the required column names (\code{INDIVIDUALS} and \code{STRATA}).
The strata column is cleaned of a white spaces that interfere with some
packages or codes: space is changed to an underscore \code{_}.
Default: \code{strata = NULL}.}

\item{pop.levels}{(optional, string) This refers to the levels in a factor. In this
case, the id of the pop.
Use this argument to have the pop ordered your way instead of the default
alphabetical or numerical order. e.g. \code{pop.levels = c("QUE", "ONT", "ALB")}
instead of the default \code{pop.levels = c("ALB", "ONT", "QUE")}.
White spaces in population names are replaced by underscore.
Default: \code{pop.levels = NULL}.}

\item{pop.labels}{(optional, string) Use this argument to rename/relabel
your pop or combine your pop. e.g. To combine \code{"QUE"} and \code{"ONT"}
into a new pop called \code{"NEW"}:
(1) First, define the levels for your pop with \code{pop.levels} argument:
\code{pop.levels = c("QUE", "ONT", "ALB")}.
(2) then, use \code{pop.labels} argument:
\code{pop.labels = c("NEW", "NEW", "ALB")}.
To rename \code{"QUE"} to \code{"TAS"}:
\code{pop.labels = c("TAS", "ONT", "ALB")}.
Default: \code{pop.labels = NULL}. If you find this too complicated,
there is also the \code{strata} argument that can do the same thing,
see below.
White spaces in population names are replaced by underscore.}

\item{pop.select}{(string, optional) Selected list of populations for
the analysis. e.g. \code{pop.select = c("QUE", "ONT")} to select \code{QUE}
and \code{ONT} population samples (out of 20 pops).
Default: \code{pop.select = NULL}}

\item{imputation.method}{(character, optional)
Methods available for map-independent imputations of missing genotype
(see details for more info):

\enumerate{
\item \code{imputation.method = "max"} Strawman imputation,
the most frequently observed genotypes (ties are broken at random).

\item \code{imputation.method = "rf"} On-the-fly-imputations using
Random Forests algorithm.

\item \code{imputation.method = "rf_pred"} Random Forests algorithm is used
as a prediction problem.

\item \code{imputation.method = "boost"} extreme gradient boosting trees.

\item \code{imputation.method = "mca"} Multiple Correspondence Analysis (in devel).

\code{imputation.method = NULL} the function will stop.
Default: \code{imputation.method = NULL}.
}}

\item{hierarchical.levels}{(character, optional) \code{c("global", "strata")}.
Should the imputations be computed by markers globally or by strata.
Historically, this was \code{"populations"}.

Note that imputing genotype globally in conjunction with
\code{imputation.method = "max"} can potentially create huge bias.
e.g. by introducing foreign genotypes/haplotypes in some populations
(see note for more info).
Default: \code{hierarchical.levels = "strata"}.}

\item{verbose}{(optional, logical) When \code{verbose = TRUE}
the function is a little more chatty during execution.
Default: \code{verbose = TRUE}.}

\item{folder}{(optional) The name of the folder created in the working 
directory to save the files/results. Default: \code{folder = NULL} will create
the folder for you with data and time.}

\item{filename}{(optional) The name of the file written to the directory.
Use the extension ".txt" at the end. 
Several info will be appended to the name of the file.
Default \code{assignment_data.txt}.}

\item{keep.gsi.files}{(logical, optional) With the default, 
the intermediate input and output gsi_sim files will be deleted from the 
directory when finished processing. I you decide to keep the files, with 
\code{keep.gsi.files = TRUE}, remember to allocate a large chunk of the disk 
space for the analysis.
Default: \code{keep.gsi.files = FALSE}}

\item{random.seed}{(integer, optional) For reproducibility, set an integer
that will be used inside function that requires randomness. With default,
a random number is generated and printed in the appropriate output.
Default: \code{random.seed = NULL}.}

\item{parallel.core}{(optional) The number of core used for parallel
execution during vcf import.
Default: \code{parallel::detectCores() - 1}.}
}
\value{
Depending on arguments selected, several files are written to the your
working directory or \code{folder}
The output in your global environment is a list. To view the assignment results
\code{$assignment} to view the ggplot2 figure \code{$plot.assignment}. 
See example below.
}
\description{
The arguments in the \code{assignment_ngs} function were tailored for the
reality of GBS/RADseq data for assignment analysis while
maintaining a reproducible workflow. Assignment are conducted using
\href{https://github.com/eriqande/gsi_sim}{gsi_sim} or 
\code{\link[adegenet]{adegenet}}. 

\itemize{
  \item \strong{Input file:} various file format are supported (see \code{data} argument below)
  \item \strong{Filters:} genotypes, markers, individuals and populations can be 
  filtered and/or selected in several ways using blacklist,
  whitelist and other arguments
  \item \strong{Cross-Validations:} Markers can be randomly selected for a classic LOO (Leave-One-Out)
  assignment or chosen based on ranked Fst for a thl
  (Training, Holdout, Leave-one-out) assignment analysis
  \item \strong{Imputations:} Map-independent imputation of missing genotype/alleles
  using Random Forest or the most frequent category.
  \item \strong{Assignment analysis:} conducted in 
  \href{https://github.com/eriqande/gsi_sim}{gsi_sim}, a tool 
  for doing and simulating genetic stock identification and 
  developed by Eric C. Anderson, or 
\href{https://github.com/thibautjombart/adegenet}{adegenet}, 
an R package developed by Thibaul Jombart
  \item \strong{Parallel:} The assignment can be conduncted on multiple CPUs
  \item \strong{Results:} Assignment results in raw or processed tables and figures
}
}
\details{
\strong{Input files:} see \pkg{radiator} \code{\link[radiator]{tidy_genomic_data}}
for detailed information about supported file format.

\strong{Imputations:}

The imputations using Random Forest requires more time to compute
and can take several
minutes and hours depending on the size of the dataset and polymorphism of
the species used. e.g. with a low polymorphic taxa, and a data set
containing 30\% missing data, 5 000 haplotypes loci and 500 individuals
will require 15 min. This is using multiple CPUs. To have your computer ready
for parallel computing during imputations follow the steps in the
(~10 min)

\strong{THL, Ranking and Fst:}

With \code{sampling.method = "ranked"}, the markers are first 
arranged by \emph{decreasing} values of Fst.
The Fst is computed with \code{\link{fst_WC84}} function, that uses a fast 
implementation of Weir and Cockerham 1984 Fst/Theta equations.
}
\note{
\code{assignment_ngs} assumes that the command line version of 
\href{https://github.com/eriqande/gsi_sim}{gsi_sim} 
is properly installed into \code{file.path(system.file(package = "assigner"), "bin", "gsi_sim")}.
Things are set up so that it will try running gsi_sim, and if it does not find it, the 
program will throw an error and ask the user to run \code{\link{install_gsi_sim}}
which will do its best to put a usable copy of gsi_sim where it is needed. 
To do so, you must be connected to the internet. If that doesn't work, you will
need to compile the program yourself, or get it yourself, and the manually copy
it to \code{file.path(system.file(package = "assigner"), "bin", "gsi_sim")}.
To compile \href{https://github.com/eriqande/gsi_sim}{gsi_sim}, follow the 
instruction here: \url{https://github.com/eriqande/gsi_sim}.
}
\examples{
\dontrun{
assignment.treefrog <- assignment_ngs(
data = "batch_1.vcf",
assignment.analysis = "gsi_sim",
whitelist.markers = "whitelist.vcf.txt",
snp.ld = NULL,
common.markers = TRUE,
marker.number = c(500, 5000, "all"),
sampling.method = "ranked",
thl = 0.3,
blacklist.id = "blacklist.id.treefrog.tsv",
subsample = 25,
iteration.subsample = 10
filename = "treefrog.txt",
keep.gsi.files = FALSE, 
strata = "strata.treefrog.tsv",
pop.levels = c("PAN", "COS")
imputation.method = NULL,
parallel.core = 12
)

Since the 'folder' argument is missing, it will be created automatically
inside your working directory.

To create a dataframe with the assignment results: 
assignment <- assignment.treefrog$assignment.

To plot the assignment using ggplot2 and facet 
(with subsample by current pop):
assignment.treefrog$plot.assignment + ggplot2::facet_grid(SUBSAMPLE~CURRENT).

To view the full range of y values = Assignment success(\%): 
assignment.treefrog$plot.assignment + 
ggplot2::facet_grid(SUBSAMPLE~CURRENT) + 
ggplot2::scale_y_continuous(limits = c(0,100)) 
To save the plot:
ggplot2::ggsave("assignment.pdf", height = 35, width = 60,dpi = 600,
units = "cm", useDingbats = FALSE)

# If you want to remove underscore in population names that contained white space:
facet_names <- c(
`some_pop` = "Some POP", 
`some_other_pop` = "This is what I want", 
`OVERALL` = "Overall")

# use the labeller in the facet_grid or facet_wrap call:
assignment.treefrog$plot.assignment + 
ggplot2::facet_grid(~CURRENT, ggplot2::labeller = ggplot2::as_labeller(facet_names)) + 
ggplot2::scale_y_continuous(limits = c(0,100)) 
figure # this one should be ok with custom naming in the facets.
}
}
\references{
Anderson, Eric C., Robin S. Waples, and Steven T. Kalinowski. (2008)
An improved method for predicting the accuracy of genetic stock identification.
Canadian Journal of Fisheries and Aquatic Sciences 65, 7:1475-1486.

Anderson, E. C. (2010) Assessing the power of informative subsets of
loci for population assignment: standard methods are upwardly biased.
Molecular ecology resources 10, 4:701-710.

Catchen JM, Amores A, Hohenlohe PA et al. (2011)
Stacks: Building and Genotyping Loci De Novo From Short-Read Sequences.
G3, 1, 171-182.

Catchen JM, Hohenlohe PA, Bassham S, Amores A, Cresko WA (2013)
Stacks: an analysis tool set for population genomics.
Molecular Ecology, 22, 3124-3140.

Weir BS, Cockerham CC (1984) Estimating F-Statistics for the
Analysis of Population Structure. Evolution, 38, 1358–1370.

Ishwaran H. and Kogalur U.B. (2015). Random Forests for Survival,
Regression and Classification (RF-SRC), R package version 1.6.1.

Ishwaran H. and Kogalur U.B. (2007). Random survival forests
for R. R News 7(2), 25-31.

Ishwaran H., Kogalur U.B., Blackstone E.H. and Lauer M.S. (2008).
Random survival forests. Ann. Appl. Statist. 2(3), 841--860.

Danecek P, Auton A, Abecasis G et al. (2011)
The variant call format and VCFtools.
Bioinformatics, 27, 2156-2158.

Purcell S, Neale B, Todd-Brown K, Thomas L, Ferreira MAR, 
Bender D, et al. 
PLINK: a tool set for whole-genome association and population-based linkage 
analyses. 
American Journal of Human Genetics. 2007: 81: 559–575. doi:10.1086/519795

Jombart T, Devillard S, Balloux F. 
Discriminant analysis of principal components: a new method for the analysis 
of genetically structured populations. 
BMC Genet. 2010:11: 94. doi:10.1186/1471-2156-11-94

Jombart T, Ahmed I. adegenet 1.3-1: new tools for the analysis 
of genome-wide SNP data. 
Bioinformatics. 2011:27: 3070–3071. doi:10.1093/bioinformatics/btr521

Raymond M. & Rousset F, (1995). 
GENEPOP (version 1.2): population genetics software for exact tests 
and ecumenicism. 
J. Heredity, 86:248-249

Rousset F. 
genepop'007: a complete re-implementation of the genepop software
for Windows and Linux.
Molecular Ecology Resources. 
2008, 8: 103-106. 
doi:10.1111/j.1471-8286.2007.01931.x
}
\seealso{
\code{gsi_sim} development page is available here: \url{https://github.com/eriqande/gsi_sim}
}
\author{
Thierry Gosselin \email{thierrygosselin@icloud.com} and Eric C. Anderson
}
